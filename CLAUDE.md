# CLAUDE.md

This file provides guidance to Claude Code when working with this codebase.

## Project Overview

Full-stack React + Hono template optimized for Cloudflare Workers deployment.

**Stack:**
- **Frontend:** React 19 + Vite + SWC + Tailwind CSS v4 + shadcn/ui
- **Backend:** Hono framework on Cloudflare Workers
- **Database:** PostgreSQL (local) / Hyperdrive (production)
- **Auth:** Better Auth with email/password
- **Package Manager:** Bun exclusively

## Project Structure

```
react-ts-fullstack/
├── apps/
│   └── web/                 # React frontend (Vite)
│       ├── src/
│       │   ├── components/ui/  # shadcn/ui components
│       │   ├── lib/            # Utilities (api.ts, utils.ts)
│       │   └── App.tsx         # Main app component
│       └── vite.config.ts      # Vite config (port 3000)
├── server/                  # Hono backend (Cloudflare Workers)
│   ├── src/
│   │   ├── db/             # Drizzle ORM schema
│   │   ├── lib/            # Auth, storage, helpers
│   │   ├── middleware/     # Hono middleware
│   │   ├── routes/         # API routes
│   │   └── app.ts          # Main Hono app
│   ├── scripts/
│   │   ├── setup.ts        # DB setup + env provisioning
│   │   └── seed.ts         # Database seeding
│   └── wrangler.toml       # Cloudflare Workers config
└── package.json            # Root scripts (monorepo)
```

## Development Commands

```bash
# Install dependencies
bun install

# Start development (frontend + backend)
bun run dev

# Start individual services
bun run dev:web      # Frontend on http://localhost:3000
bun run dev:server   # Backend on http://localhost:3001 (Node.js)

# Alternative: Wrangler dev (local Workers runtime - may not work in sandbox)
cd server && bun run dev:wrangler

# Build for production
bun run build

# Database commands
bun run db:setup     # Provision .env + migrate + seed
bun run db:push      # Push schema changes
bun run db:seed      # Run seed script

# Type checking
bun run check-types

# Linting
bun run lint
```

## Ports

| Service | Port | URL |
|---------|------|-----|
| Frontend (Vite) | 3000 | http://localhost:3000 |
| Backend (Node.js) | 3001 | http://localhost:3001 |
| PostgreSQL | 5432 | postgresql://lumea@localhost:5432/lumea |

## Database Setup

The template uses PostgreSQL locally and Cloudflare Hyperdrive in production.

### First-time setup (ephemeral sandboxes)

```bash
bun run db:setup
```

This command:
1. Creates `server/.dev.vars` from `.dev.vars.example` if missing
2. Auto-generates `BETTER_AUTH_SECRET` if not set
3. Waits for PostgreSQL to be ready
4. Runs `drizzle-kit push` to apply schema
5. Runs seed script

### Environment Variables

**Backend secrets** in `server/.dev.vars` (Wrangler local secrets):
- `DATABASE_URL` - PostgreSQL connection string
- `BETTER_AUTH_SECRET` - Auth secret (auto-generated by db:setup)

**Backend config** in `server/wrangler.toml` `[vars]`:
- `NODE_ENV` - Environment (development/production)
- `CORS_ORIGINS` - Comma-separated allowed origins
- `BETTER_AUTH_URL` - Auth base URL
- `LOG_LEVEL` - Logging level

**Frontend config** in `apps/web/.env.local` (optional):
- `VITE_API_URL` - Backend API URL (auto-detected in Daytona sandboxes)

## API Client

The frontend includes an auto-detecting API client at `apps/web/src/lib/api.ts`:

```typescript
import { api, endpoints } from "@/lib/api";

// GET request
const response = await api.get(endpoints.items);

// POST request
const response = await api.post(endpoints.items, { name: "New Item" });
```

In Daytona sandboxes, the API URL is auto-detected from the hostname.

## Authentication

Better Auth is configured with email/password authentication.

### Routes
- `POST /api/auth/sign-up` - Register
- `POST /api/auth/sign-in` - Login
- `POST /api/auth/sign-out` - Logout
- `GET /api/auth/session` - Get current session

### Protected Routes

Use the `requireAuth` middleware:

```typescript
import { requireAuth } from "../middleware/auth";

app.get("/api/protected", requireAuth, async (c) => {
  const session = c.get("session");
  return c.json({ user: session.user });
});
```

## Adding New API Routes

1. Create route file in `server/src/routes/`:

```typescript
import { Hono } from "hono";
import type { AppEnv } from "../types/app";

const app = new Hono<AppEnv>();

app.get("/", async (c) => {
  return c.json({ message: "Hello" });
});

export { app as myRoutes };
```

2. Register in `server/src/app.ts`:

```typescript
import { myRoutes } from "./routes/my-route";
app.route("/api/my-route", myRoutes);
```

## Adding Database Tables

1. Edit `server/src/db/schema.ts`:

```typescript
export const myTable = pgTable("my_table", {
  id: text("id").primaryKey(),
  name: text("name").notNull(),
  createdAt: timestamp("created_at").defaultNow(),
});
```

2. Push schema changes:

```bash
bun run db:push
```

## Cloudflare Deployment

### Backend (Workers)

1. Set secrets:
```bash
cd server
wrangler secret put BETTER_AUTH_SECRET
wrangler secret put DATABASE_URL  # or use Hyperdrive
```

2. Deploy:
```bash
bun run deploy:server
```

### Frontend (Pages)

```bash
bun run deploy:web
```

### Hyperdrive (Production Database)

1. Create Hyperdrive config:
```bash
wrangler hyperdrive create my-hyperdrive --connection-string="postgresql://..."
```

2. Uncomment in `wrangler.toml`:
```toml
[[hyperdrive]]
binding = "HYPERDRIVE"
id = "your-hyperdrive-id"
```

## Cloudflare Bindings

Pre-configured bindings (uncomment in `wrangler.toml` to enable):

- **Hyperdrive** - PostgreSQL connection pooling
- **R2** - Object storage
- **KV** - Key-value store
- **D1** - SQLite database (alternative to PostgreSQL)

## Key Files

| File | Purpose |
|------|---------|
| `server/src/app.ts` | Main Hono app with middleware |
| `server/src/db/schema.ts` | Drizzle ORM schema |
| `server/src/lib/auth.ts` | Better Auth configuration |
| `server/wrangler.toml` | Cloudflare Workers config |
| `apps/web/src/lib/api.ts` | Frontend API client |
| `apps/web/vite.config.ts` | Vite configuration |

## Notes

- Frontend uses port 3000 (not default 5173) for Lumea runner compatibility
- Backend uses Node.js + `@hono/node-server` for local development (identical Hono code)
- `concurrently` runs both services with `bun run dev`
- All components from shadcn/ui are pre-installed

## Architecture: Dev vs Production

The same Hono code runs in both environments:

```
┌─────────────────────────────────────┐
│     HONO APP (identical code)       │
│     server/src/app.ts               │
└─────────────────────────────────────┘
         ↓                    ↓
  ┌──────────────┐    ┌──────────────┐
  │  Dev Local   │    │  Production  │
  │  Node.js     │    │  Workers     │
  │  dev:node    │    │  deploy      │
  │  (sandbox)   │    │  (wrangler)  │
  └──────────────┘    └──────────────┘
        ↓                    ↓
  PostgreSQL            Hyperdrive
  (direct)              (pooled)
```

## Known Limitations

### Wrangler Dev in Sandbox Environments

**Wrangler dev does NOT work in Daytona/Docker sandbox environments.**

The `workerd` runtime (Cloudflare's local Workers simulator) has compatibility issues that cause:
- 100% CPU usage
- Infinite loops
- HTTP request timeouts

**Solution:** Use `bun run dev:node` instead, which runs the same Hono code on Node.js with `@hono/node-server`.

```bash
# ✅ Works in sandbox
bun run dev          # Uses dev:node
bun run dev:node     # Explicit Node.js server

# ❌ Does NOT work in sandbox
bun run dev:wrangler # Hangs/100% CPU
```

### Wrangler + Bun Runtime Incompatibility

**Wrangler does not support the Bun runtime.** All wrangler commands use `npx wrangler` to force Node.js execution:

```json
{
  "scripts": {
    "dev:wrangler": "npx wrangler dev",
    "build": "npx wrangler deploy --dry-run --outdir dist",
    "deploy": "npx wrangler deploy"
  }
}
```

If you see this error:
```
Wrangler does not support the Bun runtime. Please try this command again using Node.js
```

Make sure wrangler commands are prefixed with `npx`.

### Environment Compatibility

The middleware layer supports both Workers bindings (`c.env`) and Node.js (`process.env`):

```typescript
// Middleware auto-detects environment
const connectionString =
  c.env.HYPERDRIVE?.connectionString ||  // Workers + Hyperdrive
  c.env.DATABASE_URL ||                   // Workers + env var
  process.env.DATABASE_URL;               // Node.js
```

This allows the same code to run in both environments without modification.
